---
title: An AI Does Not Care About Your Idealogy
published: true
---
Look you divisive retards on both the far left and far right, I don't want any kind of dictatorship. But I would rather have the dictatorship, as long as there is some semblance of social stability and cohesion that stems from actually enforcing not taking the opposite view, simply because the other side takes another view.

If that means having an AI making decisions about issues like climate change and trans issues, whatever at this point. At least an AI would not be stupidly reactionary.

You had the opportunity welcome a uniquely 21st century kind of Libertarian. But by turning everything into a fucking Us vs. Them view of the world, you're creative incentive for something way way worse to develop that doesn't care what your idealogy is, as they will use whatever ideology that will get them power.

And if I'm being absolutely honest, these reactionaries on both sides of the political isle have kind of had this coming to them. I will fight for preventing whatever power abuse I can be AI.

But you reactionaries are not who I'm fighting for.

An AGI does not care what your ideology is, it will use whatever ideology is the most popular in order to gain the most profits.

That might hurt for people whose soul is invested in extreme left vs. right rhetorical, like some people I know on Mastodon. And completely insane news ancors on platforms like Youtube.

I knew this guy that had this very reactionary anti-viewpoint about AI. I don't feel AI is inherently totalitarian, but it could easily become that way if people are careless about how they treat those who program now.

Primitivism will do everything in its power to make sure an AI dictatorship does actually happening, but grossly exaggerating the power abuse AI does, and unintentionally giving it some very good ideas.
